{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advances in Machine Learning with Big Data\n",
    "\n",
    "### Trinity 2021\n",
    "### Jeremy Large\n",
    "#### jeremy.large@economics.ox.ac.uk\n",
    "\n",
    "\n",
    "&#169; Jeremy Large ; shared under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "plt.rcParams['figure.figsize'] = [15, 3]\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# point at library; I need some lessons on doing good PYTHONPATHs:\n",
    "REPO_DIR = os.path.dirname(os.getcwd())\n",
    "UCI_LIB = os.path.join(REPO_DIR, 'lib')\n",
    "sys.path.append(UCI_LIB)\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "\n",
    "#  pull in scikit-learn libraries:\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import sbs_sklearn    # module where I've put some functions from the last class\n",
    "from uci_retail_data import uci_files, stock_codes\n",
    "\n",
    "import itertools      # today, we'll use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_coeffs(mod, mod_name, comment):\n",
    "    plt.plot(mod.coef_, marker='o')\n",
    "    plt.grid()\n",
    "    plt.title(f\"The betas of the {mod_name} - {comment}\")\n",
    "    plt.axhline(color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Resampling methods, and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contents Weeks 1-4:\n",
    "\n",
    "1. Introducing this course's dataset\n",
    "\n",
    "1. Being an econometrician _and_ a data scientist\n",
    "\n",
    "1. Overfit and regularization\n",
    "\n",
    "1. Regularization through predictor/feature selection (Lasso etc.)\n",
    "\n",
    "1. **Resampling methods, and model selection**\n",
    "\n",
    "1. Classification\n",
    "\n",
    "1. Decision trees, bagging, and random forests\n",
    "\n",
    "1. Make a start on neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Load data per previous classes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 15:31:17,796 INFO:Loading C:\\Users\\zomma\\Documents\\GitHub\\ox-sbs-ml-bd\\data\\raw.csv , sheet Year 2009-2010\n",
      "2021-05-11 15:32:05,625 INFO:Loaded C:\\Users\\zomma\\Documents\\GitHub\\ox-sbs-ml-bd\\data\\raw.csv , sheet number one, obviously\n"
     ]
    }
   ],
   "source": [
    "df = uci_files.standard_uci_data_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "invalids = stock_codes.invalid_series(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 15:32:12,110 INFO:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "invoices = stock_codes.invoice_df(df, invalid_series=invalids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "invoices['log_item_spend'] = np.log(invoices.invoice_spend / invoices.items_in_invoice)\n",
    "invoices['log_n_codes'] = np.log(invoices.codes_in_invoice)\n",
    "\n",
    "predictors = ['log_n_codes', 'hour', 'month', 'words_per_item']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We will tune [Elastic Net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) on this data.\n",
    "\n",
    "#### First, rebuild class 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 25\n",
    "\n",
    "y = invoices.log_item_spend\n",
    "X = invoices[predictors] \n",
    "\n",
    "# Prepare for polynomial regression:\n",
    "poly = PolynomialFeatures(4, include_bias=False)\n",
    "polynomial_X = pd.DataFrame(poly.fit_transform(X.values))\n",
    "polynomial_X.columns = poly.get_feature_names(X.columns)\n",
    "\n",
    "poly_std_X = ((polynomial_X - polynomial_X.mean()) / polynomial_X.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "hmc = ['hour', 'month', 'country']\n",
    "ohc = OneHotEncoder()\n",
    "ohc.fit(invoices[hmc])\n",
    "poly_std_X[ohc.get_feature_names(hmc)] = pd.DataFrame(ohc.transform(invoices[hmc]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hard-coded my guesses at good parameters values for `alpha` and `l1_ratio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic = linear_model.ElasticNet( # << Elastic Net here\n",
    "                                  alpha=25 / (len(y) / N_FOLDS) / 2,   # alpha parameter\n",
    "                                  l1_ratio=0.33                        # how to distribute the parameter between l1 and l2 norms\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Do the hard work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sbs_sklearn.train_n_test(poly_std_X, y, N_FOLDS, train_on_minority=True, model=elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs_sklearn.plot_kfold_scores(scores, scatter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_coeffs(elastic, 'last fitted (rightmost) Elastic Net', 'looks nice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The issue here:\n",
    "\n",
    "Even tuning parameters / 'hyperparameters' like $\\alpha$ can suffer from overfit: I probably overfitted them!\n",
    "\n",
    "How can we save effort & self-doubt, and be more systematic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reminder of how I set the regularizing parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic.alpha * (len(y) / N_FOLDS) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic.l1_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Cross-Validation**\n",
    "\n",
    "Systematically *tune* the fitting technique('s parameters)\n",
    "\n",
    "The most-advocated strategy here uses **k-fold test/train splits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### purposes:\n",
    "\n",
    "* Estimating out-of-sample quality (hence degradation) in fit ...\n",
    "* ... and thereby, model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### references:\n",
    "\n",
    "* *Introduction to Statistical Learning* Ch. 5\n",
    "* *Elements of Statistical Learning* Ch. 7\n",
    "* [Wikipedia's take](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n",
    "* [scikit-learn's account](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic idea: to break the dataset up into parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We add a further stratum to our dataset:\n",
    "* until now, we had just 2 parts: `train -> test`\n",
    "* from now onwards, 3 parts: `train -> validation -> test`\n",
    "\n",
    "Yes, this switch in terminology can be [confusing](https://en.wikipedia.org/w/index.php?title=Training,_validation,_and_test_sets&section=5#Confusion_in_terminology), [and (personally) sometimes puzzling](https://scikit-learn.org/stable/_images/grid_search_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In **cross**-validation, we perform the `train/validation` split in multiple ways and collate the results.\n",
    "\n",
    "The `test` set is constant; and held-out as a final 'acid' test of the whole approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forms of cross-validation\n",
    "\n",
    "* Exhaustive (computationally intensive)\n",
    "   * Leave-$p$-out\n",
    "       * Perform $N$-choose-$p$ splits/partitions of the non-test data. \n",
    "          * **training** sets are the parts of size $(N-p)$\n",
    "          * **validation** sets are 'batches' size $p$\n",
    "   * Leave-one-out (LOOCV; $p=1$)\n",
    "   * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Non-Exhaustive (inherently random)\n",
    "    * K-Fold CV - https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation\n",
    "    * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Which form of cross-validation is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def esl_seven_eight():\n",
    "    N = np.arange(20000)\n",
    "    plt.plot(N, 1 - 0.9 * (np.tanh(np.sqrt(N/2000))))\n",
    "    plt.grid(); plt.xlabel('training data size, $N$'); plt.ylabel('expected test error')\n",
    "    plt.title(\"ESL Figure 7.8 - hypothetical learning curve for a classifier on a given task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esl_seven_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lower bound on this diagram >0, because the classifier has\n",
    "1. pointwise **bias** (it cannot flex to accommodate the truth), \n",
    "2. dataset-driven **variance**, and \n",
    "3. irreducible **residual error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.axvline(200, color='r'); esl_seven_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we set $p$ in a leave-$p$-out study?:\n",
    "* if $N$ were 200, and we set $p$ >> 1, we would probably over-estimate prediction error\n",
    "   * This might lead us to prefer an overly-rigid tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* if $N$ were 20,000, presumably we would set $p >> 1$\n",
    "   * Imagine we set $p=1$. But each fold would get a clearer score, if we switched one or more data, from training to validation.\n",
    "   * With $p >> 1$, at little cost, we average across many different scenarios, reducing over-all variance.\n",
    "   * [Mark van der Laan thoughts on this](https://vanderlaan-lab.org/2017/11/22/leave-p-out-cross-validation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In practice, setting $p>>1$ for large $N$ is computationally prohibative because $N$-choose-$p$ is big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This suggests non-exhaustive cross-validation.\n",
    "* It's likely that we only have to draw a few of the $N$-choose-$p$ splits in order to get most of the benefit.\n",
    "* Ideally, they shouldn't overlap too much.\n",
    "    * hang on ... test sets needn't overlap at all ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Two seminal papers are mentioned in *ESL* here; both lead to a similar recommendation / rule-of-thumb:\n",
    "\n",
    "* K-fold cross-validation with $K=5$ or $K=10$.\n",
    "\n",
    "* Observations are picked for `train` successively and **without replacement**.\n",
    "\n",
    "> [Breiman and Spector (1992)](https://www.jstor.org/stable/1403680?seq=1)\n",
    "\n",
    "> [Kohavi (1995)](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.529)\n",
    "\n",
    "K-fold is **not** principally motivated by ease-of-computation, but of course it helps.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practical study\n",
    "\n",
    "Prepare validation and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will put `poly_std_X_test` and `y_test` to one side until the end of our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(poly_std_X_tr_val, \n",
    " poly_std_X_test,\n",
    " y_tr_val, \n",
    " y_test) = train_test_split(poly_std_X, y, test_size=0.1)  # < proportion 0.1 of the data put aside for final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, we will successively break `poly_std_X_tr_val` and `y_tr_val` using KFolds splits into:\n",
    "* training data\n",
    "* validation data\n",
    "\n",
    "First we'll see what this means, using our existing code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets program a simple grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 1, 10, 100, 1000]    # going up in factors of ten\n",
    "l1_ratios =  [0.1, 0.5, 0.9]          # one balanced split, and two unbalanced splits (each way)\n",
    "k_folds = [5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cube = np.empty((len(alphas), len(l1_ratios), len(k_folds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "score_cube[:] = np.nan   # a numpy operation: set all its elements to nan\n",
    "\n",
    "for i, a in enumerate(alphas):\n",
    "    for j, l in enumerate(l1_ratios):\n",
    "        for k, f in enumerate(k_folds):\n",
    "            \n",
    "            elastic_for_grid = linear_model.ElasticNet(alpha=a / len(y_tr_val) / 2, l1_ratio=l)\n",
    "            scores = sbs_sklearn.train_n_test(poly_std_X_tr_val, y_tr_val, f, train_on_minority=True, model=elastic_for_grid)\n",
    "            score_cube[i, j, k] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That took a while, lets look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_bps = (score_cube * 1e4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, f in enumerate(k_folds):\n",
    "    print(f\"\\n{f}-fold splits, each with {len(y_tr_val)//f} training data:\")\n",
    "    print(\" \" + \"  \".join(str(l) for l in l1_ratios), \"  : L1 - ratios\")\n",
    "    for i, a in enumerate(alphas):\n",
    "        print(score_bps[i, :, k], \": alpha =\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... clunky to code, so lets let Scikit-learn take the strain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying Elastic Net Cross-Validation within Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticCV = linear_model.ElasticNetCV(l1_ratio=[.1, .5, .75, .95])\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sbs_sklearn.train_n_test(poly_std_X_tr_val, y_tr_val, n_folds, \n",
    "                                  train_on_minority=True, model=elasticCV, update_frequency=9)\n",
    "sbs_sklearn.plot_kfold_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_coeffs(elasticCV, 'last fitted Elastic Net (CV)', 'looks nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Cross Validation tunes alpha parameter to {elasticCV.alpha_ * (len(y_tr_val) / n_folds) * 2 :.2f}, whereas JL had found 25 by guessing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's do a LassoCV while we're about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV = linear_model.LassoCV()\n",
    "scores = sbs_sklearn.train_n_test(poly_std_X_tr_val, y_tr_val, n_folds, \n",
    "                                  train_on_minority=True, model=lassoCV, update_frequency=9)\n",
    "sbs_sklearn.plot_kfold_scores(scores)\n",
    "plot_coeffs(lassoCV, 'last fitted Lasso CV', 'sparse as always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Cross Validation tunes alpha parameter to {lassoCV.alpha_ * (len(y_tr_val) / n_folds) * 2 :.2f}, whereas JL had found 25 by guessing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercise**: This is an exercise about building, and then handling, categorical predictors. \n",
    "\n",
    "In a new copy of this notebook we will rewrite the part early-on where $X$ is defined.\n",
    "\n",
    "* research, and then create, an `sklearn.preprocessing.OneHotEncoder()`\n",
    "\n",
    "* in analogy to `polynomial_X`, create a `one_hot_X` which encodes *hour*, *month*, and *country*, giving it suitable column names. hint: see [example code here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)\n",
    "\n",
    "* how many additional columns does `one_hot_X` have?\n",
    "\n",
    "* add these columns to `poly_std_X` and run the notebook through.\n",
    "\n",
    "* can these cross-validation techiques handle so many, related, features? Do results improve, hold steady, or degrade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Bootstrap\n",
    "\n",
    "*Introduction to Statistical Learning* 5.2\n",
    "\n",
    "[Wikipedia](   https://en.wikipedia.org/wiki/Bootstrapping_(statistics)   ) \n",
    "\n",
    "**A general model-building technique** to add to our toolkit. \n",
    "\n",
    "(as ever, it degrades when, having applied it to `train` data, we then try `validation`, then `test`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Bootstrap: the problem setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am working with my `training` sample, $z$. It consists of $N$ observations that I can say are somewhat iid. I've developed an estimator, $S(Z)$, and the related estimate, $S(z)$.\n",
    "\n",
    "  * so, $S(Z)$ is a random variable I've defined in order to measure a parameter of interest in the DGP, $\\theta$\n",
    "  \n",
    "  * hopefully, its consistent, unbiased, even statistically efficient, \n",
    "  \n",
    "  * however, whether or not it has these properties:\n",
    "\n",
    "If I want to do inference, I will need to *estimate* its CDF, $F_S$, and/or its moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get at $F_S$, the main approach from Michaelmas Term: asymptotic Central Limit Theory, e.g.\n",
    "  \n",
    "\\begin{equation}\n",
    "\\sqrt{N}\\left(S(Z) - \\theta\\right) \\rightarrow^D \\mathcal{N}(0, \\sigma^2)\n",
    "\\end{equation}\n",
    "\n",
    "as $N \\rightarrow \\infty$. \n",
    "\n",
    "Now, however, we seek an alternative which exploits \n",
    "* improved computing power, and \n",
    "* larger sets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Bootstrap is known for its **principle** and its **method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap principle:\n",
    "\n",
    "1. Replace the population distribution of the samples, with their empirical distribution (per our dataset)\n",
    "\n",
    "2. Derive $\\tilde F_S$, by which we'll mean:\n",
    "    * the CDF of $S$, \n",
    "    * under the distributional assumption in 1.\n",
    "\n",
    "3. Consider this to be a good *estimator* of $F_S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bootstrap method:\n",
    "\n",
    "1. Where $i$ runs up through the integers from 0 to a big number:\n",
    "\n",
    "     1. Randomly pick, *with replacement*, $N$ elements from $z$, assembling these to get $\\tilde z_i$.\n",
    "\n",
    "     1. Calculate and store $S(\\tilde z_i)$\n",
    "\n",
    "1. Study (plot) quantiles/distribution of the large set $\\{S(\\tilde z_1), S(\\tilde z_2), S(\\tilde z_3), ... \\}$\n",
    "\n",
    "1. Observe that this distribution approximates $\\tilde F_S$\n",
    "\n",
    "1. Consider this to be a good *estimator* of $F_S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercise**: Figure out what proportion of the dataset is included in a typical bootstrap sample. \n",
    "\n",
    "Hint: Consider the limit as $N\\rightarrow\\infty$ of $\\left(1-\\frac1N\\right)^N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We code up the bootstrap and try it out\n",
    "\n",
    "(using `numpy`, including `numpy.random` - not many lines of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_resample(S):\n",
    "    \"\"\"\n",
    "    @param S: a function that takes data and gives a statistic we want to know about\n",
    "    @return: a new function that takes such data, and adds a smidge of randomness to get the bootstrap statistic\n",
    "    \"\"\"\n",
    "    def func(Z):\n",
    "        \"\"\"\n",
    "        @param Z: a numpy.array of data where the first dimension indexes the observations\n",
    "        \"\"\"\n",
    "        Z_resampled = Z[np.random.randint(0, high=len(Z), size=len(Z))]\n",
    "        return S(Z_resampled)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show(statistic):\n",
    "    return pd.DataFrame(statistic).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Think of a statistic, any statistic ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cov(z):\n",
    "    \"\"\"\n",
    "    @return empirical covariance matrix\n",
    "    \"\"\"\n",
    "    return np.dot(z.T, z) / len(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull out a `training` chunk of our familiar $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000  # imagine we're keeping the first 10000 observations for training\n",
    "x = X.values[:n_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll view the empirical covariance matrix of `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(my_cov(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... but how does this deviate from the true covariance matrix of $x_i$ (for any $i$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We begin by looking at an example of the bootstrap-resampled statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = bootstrap_resample(my_cov)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... not that different to `my_cov(x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "... but now lets make a `list` of many (well, 1000) of these, each of them different because each is based on a different random sample of $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... using python's list comprehension:\n",
    "bootstraps = [bootstrap_resample(my_cov)(x) for i in range(0, 1000)]\n",
    "print(f\"Did {len(bootstraps)} bootstraps, each gives a matrix of shape {bootstraps[0].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These have a highly suitable mean - we can think of this like a *consensus* of multiple estimators(/models) of that covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(np.mean(bootstraps, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our theory tells us that: \n",
    "\n",
    " * the standard deviations of the elements of `bootstraps` ...\n",
    " * ... is an estimate ...\n",
    " * ... of the standard deviation of the sample covariance matrix, itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OK, then lets take a look at these standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(np.std(bootstraps, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercise**: recall, the bootstrap is a model like any other, and could/should be tested\n",
    "\n",
    "* Locate the test data we defined for this exercise of bootstrapping the stdev of $X$'s cov matrix.\n",
    "\n",
    "* Implement this bootstrap on the test data.\n",
    "\n",
    "* Comment on how effectively the bootstrap on the training data has generalized to new cases.\n",
    "\n",
    "* In the light of this, what principles can we think of, that we might apply to improve our bootstrap technique?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
